name: Tourism Project Pipeline

on:
  push:
    branches:
      - main

jobs:

  register-dataset:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Install Dependencies
        run: pip install datasets huggingface_hub pandas
      - name: Upload Dataset to Hugging Face Hub
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: python scripts/register_dataset.py

  data-prep:
    needs: register-dataset
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Install Dependencies
        run: pip install pandas scikit-learn==1.6.1 datasets huggingface_hub -U
      - name: Run Data Preparation
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: python scripts/data_prep.py

  model-traning:
    needs: data-prep
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Install Dependencies
        run: pip install pandas scikit-learn==1.6.1 xgboost mlflow joblib huggingface_hub scipy numpy datasets -U
      - name: Start MLflow Server
        run: |
          nohup mlflow ui --host 0.0.0.0 --port 5000 &
          sleep 5
      - name: Model Building
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: python scripts/model_training.py

  deploy-hosting:
    runs-on: ubuntu-latest
    needs: [model-traning, data-prep, register-dataset]
    steps:
      - uses: actions/checkout@v3
      - name: Install Dependencies
        run: pip install streamlit scikit-learn==1.6.1 xgboost joblib pandas numpy datasets mlflow huggingface_hub scipy -U
      - name: Push files to Frontend Hugging Face Space
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: python scripts/deploy.py
